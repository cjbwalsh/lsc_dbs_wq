---
title: "Dispersed urban-stormwater control improved stream water quality in a catchment-scale experiment"
subtitle: "Supplementary methods C: model sampling"
author:
  - Christopher J Walsh, Sam J Imberger, Matthew J Burns, Darren G Bos, and Tim D Fletcher
date: "School of Ecosystem and Forest Sciences, The University of Melbourne, 500 Yarra Boulevard, Burnley, 3121 Victoria, Australia"
output:   
  word_document:
    reference_docx: officedown_template.docx
csl: ecol-app.csl
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, 
                      message = FALSE, error = FALSE)
library(rstan); library(loo); library(magrittr)
# Check all files on OSF are in data directory - if not download them
source("code/load_data_from_OSF.R")

# Set a directory for storing the (large) model objects: 
# I used a directory on a network drive 
# (the directory needs three sub-directories: data, model_fits and compiled_models)
mod_dir <- "[Network Drive]/git-data/lsc_dbs_wq/"


rstan_options(auto_write = TRUE)
options(mc.cores = 4)
nChains <- 4
```

This document, after preparing the water quality data compiled in `wq_data_compilation.Rmd`, samples from a hierarchy of general models (compiled in `wq_model_compilation.Rmd`) for each of the eight response variables, to estimate posterior distributions of the model parameters, predictions, and log-likelihoods. For each general model structure, the model is sampled in a two-step process.  First the model is run with autocorrelation terms (*autoT* and *autoS*).  The residuals of that model are used to calculate *autoT* (for samples with at least one other sample from the same site in the preceding 45 days, *autoT* equals the mean residual of all such samples) and autoS (for samples from L4 or D8 on days when samples were also taken from upstream sites: *autoS* equals the mean residual of such samples).  The fitted model object for each model with *autoT* and *autoS* terms (objects ending in '_st') is saved for comparison in `wq_model_selection.Rmd`. 

The script samples a total of 212 models, saving 106 final models with autocorrelations terms, as summarised in 'data/mod_summ.csv'.  This took ~13 h on a 4-cpu core system at 2.6GHz.  


```{r}
sites <- data.frame(readxl::read_excel("data/wq_data_compiled.xlsx", 
                                         sheet = "sites"))
wq_data <- data.frame(readxl::read_excel("data/wq_data_compiled.xlsx", 
                                         sheet = "wq_data"))
wq_data$date_time <- lubridate::ymd_hms(wq_data$date_time)
# centre and scale time
wq_data$t <- as.numeric(wq_data$date_time)
wq_data$t <- 3*(wq_data$t - (min(wq_data$t) + diff(range(wq_data$t))*0.5) )/ diff(range(wq_data$t))
# set grouping variables as integers (as expected by Stan)
wq_data$site_no <- as.integer(wq_data$site_no)
wq_data$stream_no <- as.integer(wq_data$stream_no)
# Leave rain1 uncentred, range 0-1.76, and median 0. Useful to have 0 as the median.
# Centre and scale rain365 and septic
wq_data$rain365 <- 3*(wq_data$rain365 - (min(wq_data$rain365) + 
                                           diff(range(wq_data$rain365))*0.5) )/ diff(range(wq_data$rain365))
wq_data$septic <- 3*(wq_data$septic - (min(wq_data$septic) + 
                                           diff(range(wq_data$septic))*0.5) )/ diff(range(wq_data$septic))

#Appropriate transformations for the eight variables
wq_data$lFRP <- log10(wq_data$FRP)
wq_data$lTP <- log10(wq_data$TP)
wq_data$lNH3 <- log10(wq_data$NH3)
wq_data$lTSS <- log10(wq_data$TSS)
wq_data$sNOx <- wq_data$NOx^0.5
wq_data$lTN <- log10(wq_data$TN)
wq_data$sEC <- wq_data$EC^0.5
wq_data$lTem <- log10(wq_data$Tem)

ys <- c("lFRP","lTP","lNH3","lTSS","lTN","sNOx","sEC","lTem")
vars <- c("frp","tp","nh3","tss","tn","nox","ec","tem")
```

A check of y distributions following transformation.  
```{r fig.width = 6.5, fig.height = 9}
par(mfrow = c(4,2))
for(i in 1:8){
  boxplot(wq_data[ys[i]][,1] ~ wq_data$sitecode, xlab = "sitecode",ylab = ys[i])
}
```

1. Sample m_1_st for FRP, TP, NOx, NH4+, TN, TSS, and EC

```{r}
#Load model objects, prepare data, and run models m_1 and m_1_st
#Model objects compiled in wq_model_compilation.Rmd
for (v in c(1:4,7)) { # for m1 - not temperature 
load(paste0(mod_dir, "compiled_models/wq_stan_m_1.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel")]
#pairs(d[,6:9])
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1,t = d$t)

fit_y_m_1 <- sampling(m_1, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1)
# print(fit_y_m_1, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a"), probs = c(0.025, 0.5, 0.975))

rm(m_1)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1_st",sep = "_"),
       sampling(m_1_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1_st",sep = "_")), pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1_st",sep = "_")) %>% 
  save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1, m_1_st)
rm(list = paste("fit",tolower(vars[v]),"m_1_st",sep = "_"))
gc() # garbage collection
}
```

1a. Sample m_1ft_st for TN, NOx

```{r}
#Load model objects, prepare data, and run models m_1 and m_1_st
#Model objects compiled in wq_model_compilation.Rmd
for (v in c(5:6)) { # for m1 - not temperature 
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel")]
#pairs(d[,6:9])
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1,t = d$t)

fit_y_m_1ft <- sampling(m_1ft, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1ft)
# print(fit_y_m_1ft, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_st",sep = "_"),
       sampling(m_1ft_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_st",sep = "_")), pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft, m_1ft_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_st",sep = "_"))
gc() # garbage collection
}
```

2. Sample m_1_c_st for FRP, TP, NH4+, and TSS

```{r}
#Load model objects, prepare data, and run models m_1_x and m_1_x_st
#Model objects compiled in wq_model_compilation.Rmd
for (v in c(1:4)) { 
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_x.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel")]
#pairs(d[,6:9])
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, t = d$t)

fit_y_m_1_c <- sampling(m_1_x, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_c)
# print(fit_y_m_1_c, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a", "b_add1"), probs = c(0.025, 0.5, 0.975))

rm(m_1_x)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_x_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1_c, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1_c_st",sep = "_"),
       sampling(m_1_x_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1_c_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1_c_st",sep = "_")), 
#       pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1_c_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1_c_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1_c, m_1_x_st)
rm(list = paste("fit",tolower(vars[v]),"m_1_c_st",sep = "_"))
gc() # garbage collection
}
```

2a. Sample m_1ft_c_st for TN, NOx

```{r}
#Load model objects, prepare data, and run models m_1_x and m_1_x_st
#Model objects compiled in wq_model_compilation.Rmd
for (v in c(5:6)) { 
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_x.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel")]
#pairs(d[,6:9])
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, t = d$t)

fit_y_m_1ft_c <- sampling(m_1ft_x, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1ft_c)
# print(fit_y_m_1ft_c, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a", "b_add1"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_x)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_x_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_c, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_c_st",sep = "_"),
       sampling(m_1ft_x_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_c_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_c_st",sep = "_")), 
#       pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_c_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_c_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_c, m_1ft_x_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_c_st",sep = "_"))
gc() # garbage collection
}
```

3. Sample m_1_cs_st for FRP, TP, NH4+,and TSS

```{r}
#Load model objects, prepare data, and run models m_1_xx and m_1_xx_st
#Model objects compiled in wq_model_compilation.Rmd
for (v in c(1:4)) { 
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$season, t = d$t)

fit_y_m_1_cs <- sampling(m_1_xx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_cs)
# print(fit_y_m_1_cs, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1_xx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1_cs, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1_cs_st",sep = "_"),
       sampling(m_1_xx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1_cs_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1_cs_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1_cs_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1_cs_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1_cs, m_1_xx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1_cs_st",sep = "_"))
gc() # garbage collection
}
```

3a. m_1ft_cs_st for NOx, TN

```{r}
#Load model objects, prepare data, and run models m_1_xx and m_1_xx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 5:6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$season, t = d$t)

fit_y_m_1ft_cs <- sampling(m_1ft_xx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_cs)
# print(fit_y_m_1ft_cs, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_cs, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_cs_st",sep = "_"),
       sampling(m_1ft_xx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_cs_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_cs_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_cs_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_cs_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_cs, m_1ft_xx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_cs_st",sep = "_"))
gc() # garbage collection
}
```

4. Sample m_1_cr_st for FRP, TP, NH4+, and TSS

```{r}
#Load model objects, prepare data, and run models m_1_xx and m_1_xx_st
#Model objects compiled in wq_model_compilation.Rmd
for (v in c(1:4)) { 
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$rain365, t = d$t)

fit_y_m_1_cr <- sampling(m_1_xx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_cr)
# print(fit_y_m_1_cr, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1_xx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1_cr, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1_cr_st",sep = "_"),
       sampling(m_1_xx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1_cr_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1_cr_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1_cr_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1_cr_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1_cr, m_1_xx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1_cr_st",sep = "_"))
gc() # garbage collection
}
```

4a. m_1ft_cr_st for NOx, TN

```{r}
#Load model objects, prepare data, and run models m_1_xx and m_1_xx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 5:6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$rain365, t = d$t)

fit_y_m_1ft_cr <- sampling(m_1ft_xx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_cr)
# print(fit_y_m_1ft_cr, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_cr, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_cr_st",sep = "_"),
       sampling(m_1ft_xx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_cr_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_cr_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_cr_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_cr_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_cr, m_1ft_xx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_cr_st",sep = "_"))
gc() # garbage collection
}
```

5. Sample m_1_csr_st for FRP, TP, NH4+, and TSS

```{r}
#Load model objects, prepare data, and run models m_1_xxx and m_1_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
for (v in c(1:4)) { 
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xxx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$season, add3 = d$rain365, t = d$t)

fit_y_m_1_csr <- sampling(m_1_xxx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_csr)
# print(fit_y_m_1_csr, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1_xxx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xxx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1_csr, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1_csr_st",sep = "_"),
       sampling(m_1_xxx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1_csr_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1_csr_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1_csr_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1_csr_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1_csr, m_1_xxx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1_csr_st",sep = "_"))
gc() # garbage collection
}
```

5a. m_1ft_csr_st for NOx, TN

```{r}
#Load model objects, prepare data, and run models m_1_xxx and m_1_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 5:6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$season, add3 = d$rain365, t = d$t)

fit_y_m_1ft_csr <- sampling(m_1ft_xxx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_csr)
# print(fit_y_m_1ft_csr, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xxx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_csr, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_csr_st",sep = "_"),
       sampling(m_1ft_xxx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_csr_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_csr_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_csr_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_csr_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_csr, m_1ft_xxx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_csr_st",sep = "_"))
gc() # garbage collection
}
```

6. m_1ft_sd_st: temperature

```{r}
#Load model objects, prepare data, and run models m_1ft_xx and m_1ft_xx_st
# Note time is a fixed effect in these models; as a random effect, it caused divergence problems and all random t values were near identical
#Model objects compiled in wq_model_compilation.Rmd
v <- 8
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$season, add2 = d$diel, t = d$t)

fit_y_m_1ft_sd <- sampling(m_1ft_xx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1ft_sd)
# print(fit_y_m_1ft_sd, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_sd, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_sd_st",sep = "_"),
       sampling(m_1ft_xx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_sd_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_sd_st",sep = "_")),
#      pars = c("b_d","b_r","b_rp","b_dp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_sd_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_sd_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_sd, m_1ft_xx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_sd_st",sep = "_"))
gc() # garbage collection
```

7. Sample m_1ft_sdr_st for temperature

```{r}
#Load model objects, prepare data, and run models m_1_xxx and m_1_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
v <- 8
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$season, add2 = d$diel, add3 = d$rain365, t = d$t)

fit_y_m_1ft_sdr <- sampling(m_1ft_xxx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_sdr)
# print(fit_y_m_1_sdr, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xxx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_sdr, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_sdr_st",sep = "_"),
       sampling(m_1ft_xxx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_sdr_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_sdr_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_sdr_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_sdr_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_sdr, m_1ft_xxx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_sdr_st",sep = "_"))
gc() # garbage collection
```

8. Sample m_1_s_st for FRP, TP, NH4+, TSS, and EC

```{r}
#Load model objects, prepare data, and run models m_1_x and m_1_x_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in c(1:4,7)){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_x.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel")]
#pairs(d[,6:9])
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$season, t = d$t)

fit_y_m_1_s <- sampling(m_1_x, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_s)
# print(fit_y_m_1_s, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a", "b_add1"), probs = c(0.025, 0.5, 0.975))

rm(m_1_x)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_x_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1_s, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1_s_st",sep = "_"),
       sampling(m_1_x_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1_s_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1_s_st",sep = "_")), 
#       pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1_s_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1_s_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1_s, m_1_x_st)
rm(list = paste("fit",tolower(vars[v]),"m_1_s_st",sep = "_"))
gc() # garbage collection
}
```

8a. Sample m_1ft_s_st for TN, NOx

```{r}
#Load model objects, prepare data, and run models m_1_x and m_1_x_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 5:6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_x.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel")]
#pairs(d[,6:9])
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$season, t = d$t)

fit_y_m_1ft_s <- sampling(m_1ft_x, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1ft_s)
# print(fit_y_m_1ft_s, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a", "b_add1"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_x)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_x_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_s, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_s_st",sep = "_"),
       sampling(m_1ft_x_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_s_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_s_st",sep = "_")), 
#       pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_s_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_s_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_s, m_1ft_x_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_s_st",sep = "_"))
gc() # garbage collection
}
```

9. Sample m_1_r_st for FRP, TP, NH4+, TSS, and EC

```{r}
#Load model objects, prepare data, and run models m_1_x and m_1_x_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in c(1:4,7)){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_x.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel")]
#pairs(d[,6:9])
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$rain365, t = d$t)

fit_y_m_1_r <- sampling(m_1_x, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_r)
# print(fit_y_m_1_r, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a", "b_add1"), probs = c(0.025, 0.5, 0.975))

rm(m_1_x)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_x_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1_r, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1_r_st",sep = "_"),
       sampling(m_1_x_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1_r_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1_r_st",sep = "_")), 
#       pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1_r_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1_r_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1_r, m_1_x_st)
rm(list = paste("fit",tolower(vars[v]),"m_1_r_st",sep = "_"))
gc() # garbage collection
}
```

9a. Sample m_1ft_r_st for TN, NOx

```{r}
#Load model objects, prepare data, and run models m_1_x and m_1_x_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 5:6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_x.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel")]
#pairs(d[,6:9])
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$rain365, t = d$t)

fit_y_m_1ft_r <- sampling(m_1ft_x, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1ft_r)
# print(fit_y_m_1ft_r, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a", "b_add1"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_x)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_x_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_r, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_r_st",sep = "_"),
       sampling(m_1ft_x_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_r_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_r_st",sep = "_")), 
#       pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_r_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_r_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_r, m_1ft_x_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_r_st",sep = "_"))
gc() # garbage collection
}
```

10. Sample m_1_sr_st for FRP, TP, NH4+, TSS, and EC

```{r}
#Load model objects, prepare data, and run models m_1_xx and m_1_xx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in c(1:4,7)){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$season, add2 = d$rain365, t = d$t)

fit_y_m_1_sr <- sampling(m_1_xx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_sr)
# print(fit_y_m_1_sr, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1_xx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1_sr, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1_sr_st",sep = "_"),
       sampling(m_1_xx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(adapt_delta = ifelse(v == 5, 0.98, 0.95))))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1_sr_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1_sr_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1_sr_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1_sr_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1_sr, m_1_xx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1_sr_st",sep = "_"))
gc() # garbage collection
}
```

10a. m_1ft_sr_st for NOx, TN

```{r}
#Load model objects, prepare data, and run models m_1_xx and m_1_xx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 5:6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$season, add2 = d$rain365, t = d$t)

fit_y_m_1ft_sr <- sampling(m_1ft_xx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_sr)
# print(fit_y_m_1ft_sr, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_sr, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_sr_st",sep = "_"),
       sampling(m_1ft_xx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_sr_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_sr_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_sr_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_sr_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_sr, m_1ft_xx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_sr_st",sep = "_"))
gc() # garbage collection
}
```

11. m_1ft_ce_st for NOx, TN

```{r}
#Load model objects, prepare data, and run models m_1_xx and m_1_xx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 5:6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$septic, t = d$t)

fit_y_m_1ft_ce <- sampling(m_1ft_xx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_ce)
# print(fit_y_m_1ft_ce, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_ce, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_ce_st",sep = "_"),
       sampling(m_1ft_xx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_ce_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_ce_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_ce_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_ce_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_ce, m_1ft_xx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_ce_st",sep = "_"))
gc() # garbage collection
}
```

11a. m_1ft_ec_int_st for NOx, TN

```{r}
#Model objects compiled in wq_model_compilation.Rmd
for(v in 5:6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx_int.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$septic, add2 = d$channel, t = d$t)

fit_y_m_1ft_ec_int <- sampling(m_1ft_xx_int, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_ec_int)
# print(fit_y_m_1ft_ec_int, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add1p","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xx_int)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx_int_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_ec_int, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_ec_int_st",sep = "_"),
       sampling(m_1ft_xx_int_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_ec_int_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_ec_int_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_ec_int_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_ec_int_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_ec_int, m_1ft_xx_int_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_ec_int_st",sep = "_"))
gc() # garbage collection
}
```

11c. m_1ft_e_int_st for NOx, TN

```{r}
#Load model objects, prepare data, and run models m_1_xx and m_1_xx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 5:6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_x_int.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$septic, t = d$t)

fit_y_m_1ft_e_int <- sampling(m_1ft_x_int, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_ec_int)
# print(fit_y_m_1ft_ec_int, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add1p","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_x_int)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_x_int_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_e_int, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_e_int_st",sep = "_"),
       sampling(m_1ft_x_int_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_e_int_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_e_int_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_e_int_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_e_int_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_e_int, m_1ft_x_int_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_e_int_st",sep = "_"))
gc() # garbage collection
}
```

11d. m_1ft_es_int_st for NOx, TN

```{r}
#Load model objects, prepare data, and run models m_1_xx and m_1_xx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 5:6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx_int.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$septic, add2 = d$season, t = d$t)

fit_y_m_1ft_es_int <- sampling(m_1ft_xx_int, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_es_int)
# print(fit_y_m_1ft_es_int, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add1p","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xx_int)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx_int_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_es_int, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_es_int_st",sep = "_"),
       sampling(m_1ft_xx_int_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_es_int_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_es_int_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_es_int_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_es_int_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_es_int, m_1ft_xx_int_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_es_int_st",sep = "_"))
gc() # garbage collection
}
```

11e. m_1ft_er_int_st for NOx, TN

```{r}
#Load model objects, prepare data, and run models m_1_xx and m_1_xx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 5:6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx_int.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$septic, add2 = d$rain365, t = d$t)

fit_y_m_1ft_er_int <- sampling(m_1ft_xx_int, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_er_int)
# print(fit_y_m_1ft_er_int, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add1p","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xx_int)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx_int_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_er_int, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_er_int_st",sep = "_"),
       sampling(m_1ft_xx_int_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_er_int_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_er_int_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_er_int_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_er_int_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_er_int, m_1ft_xx_int_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_er_int_st",sep = "_"))
gc() # garbage collection
}
```

11f. m_1ft_esr_int_st for NOx, TN

```{r}
#Load model objects, prepare data, and run models m_1_xxx and m_1_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 5:6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx_int.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$septic, add2 = d$season, add3 = d$rain365, t = d$t)

fit_y_m_1ft_esr_int <- sampling(m_1ft_xxx_int, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_esr_int)

rm(m_1ft_xxx_int)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx_int_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_esr_int, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_esr_int_st",sep = "_"),
       sampling(m_1ft_xxx_int_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) 
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_esr_int_st",sep = "_")))
get(paste("fit",tolower(vars[v]),"m_1ft_esr_int_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_esr_int_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_esr_int, m_1ft_xxx_int_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_esr_int_st",sep = "_"))
gc() # garbage collection
}
```

12. Sample m_1ft_cse_st for NOx, TN

```{r eval = TRUE}
#Load model objects, prepare data, and run models m_1ft_xxx and m_1ft_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in c(5:6)){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$season, add3 = d$septic, t = d$t)

fit_y_m_1ft_cse <- sampling(m_1ft_xxx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))
# check_hmc_diagnostics(fit_y_m_1ft_cse)
# print(fit_y_m_1ft_cse, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xxx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_cse, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_cse_st",sep = "_"),
       sampling(m_1ft_xxx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_cse_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_cse_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_cse_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_cse_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_cse, m_1ft_xxx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_cse_st",sep = "_"))
gc() # garbage collection
}
```

13. Sample m_1_cre_st for NOx, TN

```{r eval = TRUE}
#Load model objects, prepare data, and run models m_1ft_xxx and m_1ft_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in c(5:6)){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$rain365, add3 = d$septic, t = d$t)

fit_y_m_1ft_cre <- sampling(m_1ft_xxx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))
# check_hmc_diagnostics(fit_y_m_1ft_cre)
# print(fit_y_m_1ft_cre, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xxx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_cre, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_cre_st",sep = "_"),
       sampling(m_1ft_xxx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_cre_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_cre_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_cre_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_cre_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_cre, m_1ft_xxx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_cre_st",sep = "_"))
gc() # garbage collection
}
```

14. Sample m_2ft_sd_int_st for temperature

```{r eval = TRUE}
#Model objects compiled in wq_model_compilation.Rmd
for(v in c(8)){
load(paste0(mod_dir, "compiled_models/wq_stan_m_2ft_sd_int.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, season = d$season, diel = d$diel, t = d$t)

fit_y_m_2ft_sd_int <- sampling(m_2ft_sd_int, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_cre)
# print(fit_y_m_1_cre, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_2ft_sd_int)
load(paste0(mod_dir, "compiled_models/wq_stan_m_2ft_sd_int_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_2ft_sd_int, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_2ft_sd_int_st",sep = "_"),
       sampling(m_2ft_sd_int_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1_cre_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1_cre_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_2ft_sd_int_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_2ft_sd_int_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_2ft_sd_int,m_2ft_sd_int_st)
rm(list = paste("fit",tolower(vars[v]),"m_2ft_sd_int_st",sep = "_"))
gc() # garbage collection
}
```

15. Sample m_2ft_sdr_int_st for temperature

```{r eval = TRUE}
#Load model objects, prepare data, and run models m_1_xxx and m_1_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in c(8)){
load(paste0(mod_dir, "compiled_models/wq_stan_m_2ft_sdr_int.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, season = d$season, diel = d$diel, rain365 = d$rain365,t = d$t)

fit_y_m_2ft_sdr_int <- sampling(m_2ft_sdr_int, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_cre)
# print(fit_y_m_1_cre, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_2ft_sdr_int)
load(paste0(mod_dir, "compiled_models/wq_stan_m_2ft_sdr_int_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_2ft_sdr_int, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_2ft_sdr_int_st",sep = "_"),
       sampling(m_2ft_sdr_int_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_2ft_sdr_int_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_2ft_sdr_int_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_2ft_sdr_int_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_2ft_sdr_int_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_2ft_sdr_int,m_2ft_sdr_int_st)
rm(list = paste("fit",tolower(vars[v]),"m_2ft_sdr_int_st",sep = "_"))
gc() # garbage collection
}
```

14. Sample m_3ft_sd_int_st for temperature

```{r eval = TRUE}
#Model objects compiled in wq_model_compilation.Rmd
for(v in c(8)){
load(paste0(mod_dir, "compiled_models/wq_stan_m_3ft_sd_int.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, season = d$season, diel = d$diel, t = d$t)

fit_y_m_3ft_sd_int <- sampling(m_3ft_sd_int, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_3ft_sd_int)
# print(fit_y_m_1_cre, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_3ft_sd_int)
load(paste0(mod_dir, "compiled_models/wq_stan_m_3ft_sd_int_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_3ft_sd_int, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_3ft_sd_int_st",sep = "_"),
       sampling(m_3ft_sd_int_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_3ft_sd_int_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_3ft_sd_int_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_3ft_sd_int_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_3ft_sd_int_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_3ft_sd_int,m_3ft_sd_int_st)
rm(list = paste("fit",tolower(vars[v]),"m_3ft_sd_int_st",sep = "_"))
gc() # garbage collection
}
```

15. Sample m_3ft_sdr_int_st for temperature

```{r eval = TRUE}
#Load model objects, prepare data, and run models m_1_xxx and m_1_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in c(8)){
load(paste0(mod_dir, "compiled_models/wq_stan_m_3ft_sdr_int.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, season = d$season, diel = d$diel, rain365 = d$rain365,t = d$t)

fit_y_m_3ft_sdr_int <- sampling(m_3ft_sdr_int, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_cre)
# print(fit_y_m_1_cre, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_3ft_sdr_int)
load(paste0(mod_dir, "compiled_models/wq_stan_m_3ft_sdr_int_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_3ft_sdr_int, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_3ft_sdr_int_st",sep = "_"),
       sampling(m_3ft_sdr_int_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_3ft_sdr_int_st",sep = "_")))
get(paste("fit",tolower(vars[v]),"m_3ft_sdr_int_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_3ft_sdr_int_st",sep = "_"),".rda"))
rm(y_pred, m_3ft_sdr_int_st, fit_y_m_3ft_sdr_int)
rm(list = paste("fit",tolower(vars[v]),"m_3ft_sdr_int_st",sep = "_"))
gc() # garbage collection
}
```

All model structures with *filter* variable for FRP, NH3 and NOx

f1: m_1_f

```{r}
#Load model objects, prepare data, and run models m_1_x and m_1_x_st
#Model objects compiled in wq_model_compilation.Rmd
for (v in c(1,3)) { 
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_x.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$filter, t = d$t)

fit_y_m_1_f <- sampling(m_1_x, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_f)
# print(fit_y_m_1_f, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a", "b_add1"), probs = c(0.025, 0.5, 0.975))

rm(m_1_x)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_x_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1_f, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1_f_st",sep = "_"),
       sampling(m_1_x_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1_f_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1_f_st",sep = "_")), 
#       pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1_f_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1_f_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1_f, m_1_x_st)
rm(list = paste("fit",tolower(vars[v]),"m_1_f_st",sep = "_"))
gc() # garbage collection
}
```

f1a: m_1ft_f

```{r}
#Load model objects, prepare data, and run models m_1_x and m_1_x_st
#Model objects compiled in wq_model_compilation.Rmd
for (v in c(6)) { 
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_x.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","filter")]
#pairs(d[,6:9])
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$filter, t = d$t)

fit_y_m_1ft_f <- sampling(m_1ft_x, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1ft_f)
# print(fit_y_m_1ft_f, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a", "b_add1"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_x)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_x_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_f, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_f_st",sep = "_"),
       sampling(m_1ft_x_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_f_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_f_st",sep = "_")), 
#       pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_f_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_f_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_f, m_1ft_x_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_f_st",sep = "_"))
gc() # garbage collection
}
```

f2: m_1_cf

```{r}
#Load model objects, prepare data, and run models m_1_xx and m_1_xx_st
#Model objects compiled in wq_model_compilation.Rmd
for (v in c(1,3)) { 
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$filter, t = d$t)

fit_y_m_1_cf <- sampling(m_1_xx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_cf)
# print(fit_y_m_1_cf, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1_xx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1_cf, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1_cf_st",sep = "_"),
       sampling(m_1_xx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1_cf_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1_cf_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1_cf_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1_cf_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1_cf, m_1_xx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1_cf_st",sep = "_"))
gc() # garbage collection
}
```

f2a: m_1ft_cf

```{r}
#Load model objects, prepare data, and run models m_1_xx and m_1_xx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$filter, t = d$t)

fit_y_m_1ft_cf <- sampling(m_1ft_xx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_cf)
# print(fit_y_m_1ft_cf, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_cf, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_cf_st",sep = "_"),
       sampling(m_1ft_xx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_cf_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_cf_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_cf_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_cf_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_cf, m_1ft_xx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_cf_st",sep = "_"))
gc() # garbage collection
}
```

f3: m_1_rf

```{r}
#Load model objects, prepare data, and run models m_1_xx and m_1_xx_st
#Model objects compiled in wq_model_compilation.Rmd
for (v in c(1,3)) { 
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$rain365, add2 = d$filter, t = d$t)

fit_y_m_1_rf <- sampling(m_1_xx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_rf)
# print(fit_y_m_1_rf, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1_xx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1_rf, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1_rf_st",sep = "_"),
       sampling(m_1_xx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1_rf_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1_rf_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1_rf_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1_rf_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1_rf, m_1_xx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1_rf_st",sep = "_"))
gc() # garbage collection
}
```

f3a: m_1ft_rf

```{r}
#Load model objects, prepare data, and run models m_1_xx and m_1_xx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$rain365, add2 = d$filter, t = d$t)

fit_y_m_1ft_rf <- sampling(m_1ft_xx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_rf)
# print(fit_y_m_1ft_rf, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_rf, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_rf_st",sep = "_"),
       sampling(m_1ft_xx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_rf_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_rf_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_rf_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_rf_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_rf, m_1ft_xx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_rf_st",sep = "_"))
gc() # garbage collection
}
```

f4: m_1_sf

```{r}
#Load model objects, prepare data, and run models m_1_xx and m_1_xx_st
#Model objects compiled in wq_model_compilation.Rmd
for (v in c(1,3)) { 
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$season, add2 = d$filter, t = d$t)

fit_y_m_1_sf <- sampling(m_1_xx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_sf)
# print(fit_y_m_1_sf, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1_xx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1_sf, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1_sf_st",sep = "_"),
       sampling(m_1_xx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1_sf_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1_sf_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1_sf_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1_sf_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1_sf, m_1_xx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1_sf_st",sep = "_"))
gc() # garbage collection
}
```

f4a: m_1ft_sf

```{r}
#Load model objects, prepare data, and run models m_1_xx and m_1_xx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$season, add2 = d$filter, t = d$t)

fit_y_m_1ft_sf <- sampling(m_1ft_xx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_sf)
# print(fit_y_m_1ft_sf, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_sf, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_sf_st",sep = "_"),
       sampling(m_1ft_xx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_sf_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_sf_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_sf_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_sf_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_sf, m_1ft_xx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_sf_st",sep = "_"))
gc() # garbage collection
}
```

f5. m_1_crf

```{r}
#Load model objects, prepare data, and run models m_1_xxx and m_1_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
for (v in c(1,3)) { 
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xxx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$rain365, add3 = d$filter, t = d$t)

fit_y_m_1_crf <- sampling(m_1_xxx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_crf)
# print(fit_y_m_1_crf, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1_xxx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xxx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1_crf, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1_crf_st",sep = "_"),
       sampling(m_1_xxx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1_crf_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1_crf_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1_crf_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1_crf_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1_crf, m_1_xxx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1_crf_st",sep = "_"))
gc() # garbage collection
}
```

f5a. m_1ft_crf_st

```{r}
#Load model objects, prepare data, and run models m_1_xxx and m_1_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$rain365, add3 = d$filter, t = d$t)

fit_y_m_1ft_crf <- sampling(m_1ft_xxx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_crf)
# print(fit_y_m_1ft_crf, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2","b_add3"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xxx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_crf, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_crf_st",sep = "_"),
       sampling(m_1ft_xxx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_crf_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_crf_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_crf_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_crf_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_crf, m_1ft_xxx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_crf_st",sep = "_"))
gc() # garbage collection
}
```

f6. m_1_csf

```{r}
#Load model objects, prepare data, and run models m_1_xxx and m_1_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
for (v in c(1,3)) { 
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xxx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$season, add3 = d$filter, t = d$t)

fit_y_m_1_csf <- sampling(m_1_xxx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_csf)
# print(fit_y_m_1_csf, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1_xxx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xxx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1_csf, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1_csf_st",sep = "_"),
       sampling(m_1_xxx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1_csf_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1_csf_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1_csf_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1_csf_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1_csf, m_1_xxx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1_csf_st",sep = "_"))
gc() # garbage collection
}
```

f6a. m_1ft_csf_st

```{r}
#Load model objects, prepare data, and run models m_1_xxx and m_1_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$season, add3 = d$filter, t = d$t)

fit_y_m_1ft_csf <- sampling(m_1ft_xxx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_csf)
# print(fit_y_m_1ft_csf, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2","b_add3"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xxx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_csf, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_csf_st",sep = "_"),
       sampling(m_1ft_xxx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_csf_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_csf_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_csf_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_csf_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_csf, m_1ft_xxx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_csf_st",sep = "_"))
gc() # garbage collection
}
```

f7. m_1_srf

```{r}
#Load model objects, prepare data, and run models m_1_xxx and m_1_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
for (v in c(1,3)) { 
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xxx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$season, add2 = d$rain365, add3 = d$filter, t = d$t)

fit_y_m_1_srf <- sampling(m_1_xxx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_srf)
# print(fit_y_m_1_srf, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1_xxx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xxx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1_srf, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1_srf_st",sep = "_"),
       sampling(m_1_xxx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1_srf_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1_srf_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1_srf_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1_srf_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1_srf, m_1_xxx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1_srf_st",sep = "_"))
gc() # garbage collection
}
```

f7a. m_1ft_srf_st

```{r}
#Load model objects, prepare data, and run models m_1_xxx and m_1_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$season, add2 = d$rain365, add3 = d$filter, t = d$t)

fit_y_m_1ft_srf <- sampling(m_1ft_xxx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_srf)
# print(fit_y_m_1ft_srf, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2","b_add3"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xxx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_srf, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_srf_st",sep = "_"),
       sampling(m_1ft_xxx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_srf_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_srf_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_srf_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_srf_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_srf, m_1ft_xxx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_srf_st",sep = "_"))
gc() # garbage collection
}
```

f8. m_1ft_cef_st

```{r}
#Load model objects, prepare data, and run models m_1_xxx and m_1_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$septic, add3 = d$filter, t = d$t)

fit_y_m_1ft_cef <- sampling(m_1ft_xxx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_cef)
# print(fit_y_m_1ft_cef, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2","b_add3"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xxx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_cef, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_cef_st",sep = "_"),
       sampling(m_1ft_xxx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_cef_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_cef_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_cef_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_cef_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_cef, m_1ft_xxx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_cef_st",sep = "_"))
gc() # garbage collection
}
```

f9. m_1_csrf

```{r}
#Load model objects, prepare data, and run models m_1_xxxx and m_1_xxxx_st
#Model objects compiled in wq_model_compilation.Rmd
for (v in c(1,3)) { 
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xxxx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$season, 
            add3 = d$rain365, add4 = d$filter, t = d$t)

fit_y_m_1_csrf <- sampling(m_1_xxxx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains) 
# check_hmc_diagnostics(fit_y_m_1_csrf)
# print(fit_y_m_1_csrf, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2","b_add3","b_add4"), probs = c(0.025, 0.5, 0.975))

rm(m_1_xxxx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1_xxxx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1_csrf, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1_csrf_st",sep = "_"),
       sampling(m_1_xxxx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1_csrf_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1_csrf_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1_csrf_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1_csrf_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1_csrf, m_1_xxxx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1_csrf_st",sep = "_"))
gc() # garbage collection
}
```

f9a. m_1ft_csrf_st

```{r}
#Load model objects, prepare data, and run models m_1_xxxx and m_1_xxxx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxxx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$season, 
            add3 = d$rain365, add4 = d$filter, t = d$t)

fit_y_m_1ft_csrf <- sampling(m_1ft_xxxx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_csrf)
# print(fit_y_m_1ft_csrf, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2","b_add3"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xxxx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxxx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_csrf, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_csrf_st",sep = "_"),
       sampling(m_1ft_xxxx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_csrf_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_csrf_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_csrf_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_csrf_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_csrf, m_1ft_xxxx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_csrf_st",sep = "_"))
gc() # garbage collection
}
```

f10. m_1ft_csef_st

```{r}
#Load model objects, prepare data, and run models m_1_xxxx and m_1_xxxx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxxx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$season, 
            add3 = d$septic, add4 = d$filter, t = d$t)

fit_y_m_1ft_csef <- sampling(m_1ft_xxxx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_csef)
# print(fit_y_m_1ft_csef, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2","b_add3"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xxxx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxxx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_csef, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_csef_st",sep = "_"),
       sampling(m_1ft_xxxx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_csef_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_csef_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_csef_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_csef_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_csef, m_1ft_xxxx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_csef_st",sep = "_"))
gc() # garbage collection
}
```

f11. m_1ft_cref_st

```{r}
#Load model objects, prepare data, and run models m_1_xxxx and m_1_xxxx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxxx.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$channel, add2 = d$rain365, 
            add3 = d$septic, add4 = d$filter, t = d$t)

fit_y_m_1ft_cref <- sampling(m_1ft_xxxx, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_cref)
# print(fit_y_m_1ft_cref, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add2","b_add3"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xxxx)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxxx_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_cref, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_cref_st",sep = "_"),
       sampling(m_1ft_xxxx_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_cref_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_cref_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_cref_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_cref_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_cref, m_1ft_xxxx_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_cref_st",sep = "_"))
gc() # garbage collection
}
```

f12: m_1ft_ecf_int

```{r}
#Load model objects, prepare data, and run models m_1_xxx and m_1_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx_int.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$septic, add2 = d$channel, add3 = d$filter, t = d$t)

fit_y_m_1ft_ecf_int <- sampling(m_1ft_xxx_int, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_ecf_int)
# print(fit_y_m_1ft_ecf_int, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add1p","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xxx_int)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx_int_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_ecf_int, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_ecf_int_st",sep = "_"),
       sampling(m_1ft_xxx_int_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_ecf_int_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_ecf_int_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_ecf_int_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_ecf_int_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_ecf_int, m_1ft_xxx_int_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_ecf_int_st",sep = "_"))
gc() # garbage collection
}
```

f13: m_1ft_erf_int

```{r}
#Load model objects, prepare data, and run models m_1_xxx and m_1_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx_int.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$septic, add2 = d$rain365, add3 = d$filter, t = d$t)

fit_y_m_1ft_erf_int <- sampling(m_1ft_xxx_int, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_erf_int)
# print(fit_y_m_1ft_erf_int, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add1p","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xxx_int)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx_int_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_erf_int, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_erf_int_st",sep = "_"),
       sampling(m_1ft_xxx_int_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_erf_int_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_erf_int_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_erf_int_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_erf_int_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_erf_int, m_1ft_xxx_int_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_erf_int_st",sep = "_"))
gc() # garbage collection
}
```

f14: m_1ft_esf_int

```{r}
#Load model objects, prepare data, and run models m_1_xxx and m_1_xxx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx_int.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$septic, add2 = d$season, add3 = d$filter, t = d$t)

fit_y_m_1ft_esf_int <- sampling(m_1ft_xxx_int, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_esf_int)
# print(fit_y_m_1ft_esf_int, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add1p","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xxx_int)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxx_int_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_esf_int, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_esf_int_st",sep = "_"),
       sampling(m_1ft_xxx_int_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_esf_int_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_esf_int_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_esf_int_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_esf_int_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_esf_int, m_1ft_xxx_int_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_esf_int_st",sep = "_"))
gc() # garbage collection
}
```

f15: m_1ft_ef_int

```{r}
#Load model objects, prepare data, and run models m_1_xx_int and m_1_xx_int_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx_int.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$septic, add2 = d$filter, t = d$t)

fit_y_m_1ft_ef_int <- sampling(m_1ft_xx_int, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_ef_int)
# print(fit_y_m_1ft_ef_int, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add1p","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xx_int)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xx_int_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_ef_int, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_ef_int_st",sep = "_"),
       sampling(m_1ft_xx_int_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_ef_int_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_ef_int_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_ef_int_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_ef_int_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_ef_int, m_1ft_xx_int_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_ef_int_st",sep = "_"))
gc() # garbage collection
}
```

f14: m_1ft_esf_int

```{r}
#Load model objects, prepare data, and run models m_1_xxxx and m_1_xxxx_st
#Model objects compiled in wq_model_compilation.Rmd
for(v in 6){
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxxx_int.rda"))
d <- wq_data[c("samplecode","sitecode","site_no","stream_no","date_time","t",
               "degrd","restr","rain1","rain365","channel","season","diel","septic","filter")]
d$y <- wq_data[ys[v]][,1]
d <- d[!is.na(d$y),] #dim(d)[1] 2251 cf 2299 for wq_data
#Centre the predictor to make search for intercept more efficient
d$y <- d$y - (min(d$y) + diff(range(d$y))*0.5)
d$y <- 1.5 * d$y / max(d$y)

dat <- list(N = nrow(d), N_site_no = length(unique(d$site_no)), y = d$y, 
            site_no = d$site_no, degrd = d$degrd, restr = d$restr, 
            rain1 = d$rain1, add1 = d$septic, add2 = d$season, add3 = d$rain365, 
            add4 = d$filter, t = d$t)

fit_y_m_1ft_esrf_int <- sampling(m_1ft_xxxx_int, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15)) 
# check_hmc_diagnostics(fit_y_m_1ft_esrf_int)
# print(fit_y_m_1ft_esrf_int, pars = c("b_d","b_r","b_dp","b_rp","b_p","b_t","a_s","a","b_add1","b_add1p","b_add2"), probs = c(0.025, 0.5, 0.975))

rm(m_1ft_xxxx_int)
load(paste0(mod_dir, "compiled_models/wq_stan_m_1ft_xxxx_int_st.rda"))
# extract posterior predictions of mu for each data point
y_pred <- as.data.frame(fit_y_m_1ft_esrf_int, include = TRUE, pars = 'mu')
y_pred_mean <- apply(y_pred, 2, mean)
d$non_auto_resids <- d$y - y_pred_mean
d$auto_t <- NA
  for(j in 1:length(sites$sitecode)){
    di <- d[d$sitecode == sites$sitecode[j],]
    di <- di[order(di$date_time),]
    for(k in 1:dim(di)[1]){
    di$auto_t[k] <- 
        mean(di$non_auto_resids[di$date_time >= di$date_time[k] - lubridate::days(45) & 
                                   di$date_time < di$date_time[k]])
    }
    d$auto_t[match(di$samplecode,d$samplecode)] <- di$auto_t
  }
missing_index <- which(is.na(d$auto_t))
no_missing_index <- which(!is.na(d$auto_t_y))
d$auto_s <- NA  
wq_dbs8 <- d$samplecode[d$sitecode == "DBS0008"]
for(i in 1:length(wq_dbs8)){
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004") == 1){
  d$auto_s[d$samplecode == wq_dbs8[i]] <- 
    d$non_auto_resids[as.Date(d$date_time) == as.Date(d$date_time)[d$samplecode == wq_dbs8[i]] & d$sitecode == "DBS0004"]
  }
}
wq_lis4 <- d$samplecode[d$sitecode == "LIS0004"]
wq_lis <- d[d$sitecode %in% c("LIS0004","LIS0001","LSN0001","LSS0001"),]
wq_lis$date <- as.Date(wq_lis$date_time)
wq_lis <- wq_lis[wq_lis$date > as.Date("2011-03-03"),]  #after tribs began to be sampled
lis_dates <- unique(wq_lis$date)
for(i in 1:length(lis_dates)){
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") > 1) stop()
  if(sum(as.Date(d$date_time) == lis_dates[i] & d$sitecode == "LIS0004") == 1){
    wq_lisi <- wq_lis[wq_lis$date == lis_dates[i] & wq_lis$sitecode != "LIS0004",]
  d$auto_s[d$samplecode ==wq_lis$samplecode[wq_lis$date == lis_dates[i] & wq_lis$sitecode == "LIS0004"]] <- mean(d$non_auto_resids[as.Date(d$date_time) == lis_dates[i] & d$sitecode %in% c("LIS0001","LSN0001","LSS0001")])
  }
}
auto_t <- d$auto_t; auto_t[is.na(auto_t)] <- 9999
auto_s <- d$auto_s; auto_s[is.na(auto_s)] <- 9999
dat$auto_t <- auto_t
dat$auto_s <- auto_s
dat$n_st_miss <- as.integer(sum(is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_s_miss <- as.integer(sum(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$n_t_miss <- as.integer(sum(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$n_no_miss <- as.integer(sum(!is.na(d$auto_s) & !is.na(d$auto_t)))
dat$st_miss <- as.integer(which(is.na(d$auto_s) & is.na(d$auto_t)))
dat$s_miss <- as.integer(which(is.na(d$auto_s) & !is.na(d$auto_t)))
dat$t_miss <- as.integer(which(!is.na(d$auto_s) & is.na(d$auto_t)))
dat$no_miss <- as.integer(which(!is.na(d$auto_s) & !is.na(d$auto_t)))

assign(paste("fit",tolower(vars[v]),"m_1ft_esrf_int_st",sep = "_"),
       sampling(m_1ft_xxxx_int_st, data=dat, iter=2000, warmup = 1000, 
                    cores = 4, chains = nChains, control = list(max_treedepth = 15))) #adapt_delta = ifelse(v == 5, 0.98, 0.95))
# check_hmc_diagnostics(get(paste("fit",tolower(vars[v]),"m_1ft_esrf_int_st",sep = "_")))
# print(get(paste("fit",tolower(vars[v]),"m_1ft_esrf_int_st",sep = "_")), 
#       pars = c("b_d","b_r","b_rp","b_p","b_t","a_s","a","b_auto_t","b_auto_s","b_add1","b_add2"), probs = c(0.025, 0.5, 0.975))
get(paste("fit",tolower(vars[v]),"m_1ft_esrf_int_st",sep = "_")) %>% save(file = paste0(mod_dir, "model_fits/",
              paste("fit",tolower(vars[v]),"m_1ft_esrf_int_st",sep = "_"),".rda"))
rm(y_pred, fit_y_m_1ft_esrf_int, m_1ft_xxxx_int_st)
rm(list = paste("fit",tolower(vars[v]),"m_1ft_esrf_int_st",sep = "_"))
gc() # garbage collection
}
```


