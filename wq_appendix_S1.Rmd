---
title: "Dispersed urban-stormwater control improved stream water quality in a catchment-scale experiment"
subtitle: "Appendix S1. Statistical methods and code"
author:
  - Christopher J Walsh, Sam J Imberger, Matthew J Burns, Darren G Bos, and Tim D Fletcher
date: "School of Ecosystem and Forest Sciences, The University of Melbourne, 500 Yarra Boulevard, Burnley, 3121 Victoria, Australia"
output:   
  word_document:
    reference_docx: officedown_template.docx
csl: ecol-app.csl
bibliography: lsc_dbs_wq.bib
editor_options: 
  markdown: 
    wrap: 120
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
# Packages required to run chunks in this document
requiredPackages <- c("flextable","readxl","here","rstan","scales","knitr")
lapply(requiredPackages, require, character.only = TRUE, quietly = TRUE)
# Bespoke functions used in the document (table_for_word(),)
source("code/misc_functions.R")  
# Check all files on OSF are in data directory - if not download them
source("load_data_from_OSF.R")
```

## Introduction

This document describes the methods used to construct the hierarchical linear models used in the paper, "Dispersed
stormwater control of stream water quality: a catchment-scale experiment" by Walsh et al., to assess the effects of
dispersed stormwater control measures on stream water quality. All of the code and data used in the manuscript and
described in this document are publicly available at <https://osf.io/4ywvq/>, and the linked github repository
[\<https://github.com/cjbwalsh/lsc_dbs_scms\>](https://github.com/cjbwalsh/lsc_dbs_scms){.uri}. If you clone the
repository to your local computer, running the script `code/load_data_from_OSF.R` will ensure that data files on OSF are
downloaded to the local appropriate directory. `load_data_from_OSF.R` is run at the start of each of the RMarkdown
documents described below, and the RMarkdown version of this document.

We constructed the models using seven RMarkdown [@allaire2021] documents:

-   `wq_methods_A_data_compilation.Rmd` records the process of extracting, checking, and cleaning water quality and
    predictor data from the project database, and compiling it into the file `wq_data_compiled.xlsx`, for use in the
    models.

-   `wq_methods_B_model_compilation.Rmd` contains the Stan [@CarpenterEtAl_2017] code for all models, saving each
    compiled model as an R object.

-   `wq_methods_C_model_sampling.Rmd` samples each model for each water quality variable to derive posterior estimates
    for parameters, data points, and log-likelihoods to permit calculation of 'leave-one-out' information criteria
    (looIC), saving each fitted model as an R object.

-   `wq_methods_D_model_selection.Rmd` calculates the looIC for each model, and compares all models to select the best
    model for each variable.

-   `wq_methods_E_model_compilation_with_Xpred.Rmd` contains the Stan [@CarpenterEtAl_2017] code for the selected best
    models, calculating the additional generated quantities of posterior predictions to the 'test' set of predictors
    used to plot scenario predictions in the paper. Each compiled model was saved as an R object.

-   `wq_methods_F_model_sampling_with_Xpred.Rmd` samples each selected best model for each water quality variable to
    derive posterior estimates as above, but also including posterior estimates of responses to the test set of
    predictors

-   `wq_methods_G_model_prediction.Rmd` prepares tables of model predictions used to produce the figures in this
    document and the main paper.

Here, we provide an overview of the data used, and the model structures, diagnostics, fits, and selection. More detail
can be found in the relevant RMarkdown documents.

## Data

The code in `wq_methods_A_data_compilation.Rmd` compiled the data into an excel file, `data/wq_data_compiled.xlsx`, with
5 worksheets, 'sites', 'wq_data', 'wq_vars', 'new_X', and 'metadata'. The code requires access to databases on Melbourne
University servers: it is provided to record the process of data compilation.

Data specific to each of the 11 sites is recorded in the 'sites' worksheet. For more information on each of these sites,
see @WalshEtAl_2021, and its supplementary material and data at <https://doi.org/10.17605/OSF.IO/57AZQ>. Fig 2 in that
paper is a map of the site locations, illustrating patterns of impervious coverage and connection in the catchments of
the 11 sites. Data specific to each of the 8 water quality variables is recorded in the 'wq_vars' table (units, methods,
detection limits).

The 'wq_data' table contains all of the relevant predictor and response variable data for 2,299 samples, each with a
unique samplecode, a sitecode that links to the sites table, and a date and time when the sample was taken. Values of
the 10 predictor variables in this table are transformed to reduce leverage in the models, but, other than *t*, were not
centered or standardised. (They were centered and standardised, as required, in `wq_methods_C_model_sampling.Rmd`).
There was little correlation among the predictors (Fig. S1-1), except between *t*, the time variable, and *filter,* the
variable differentiating samples taken with different filters (see below).

```{r fig.width = 6.5, fig.height = 6.5}
sites <- data.frame(readxl::read_excel("data/wq_data_compiled.xlsx", 
                                         sheet = "sites"))
wq_data <- data.frame(readxl::read_excel("data/wq_data_compiled.xlsx", 
                                         sheet = "wq_data"))
wq_data$date_time <- lubridate::ymd_hms(wq_data$date_time)
# centre and scale time
wq_data$t <- as.numeric(wq_data$date_time)
wq_data$t <- 3*(wq_data$t - (min(wq_data$t) + diff(range(wq_data$t))*0.5) )/ diff(range(wq_data$t))
# set grouping variables as integers (as expected by Stan)
wq_data$site_no <- as.integer(wq_data$site_no)
wq_data$stream_no <- as.integer(wq_data$stream_no)
# Leave rain1 uncentred, range 0-1.76, and median 0. Useful to have 0 as the median.
# Centre and scale rain365 and septic
wq_data$rain365 <- 3*(wq_data$rain365 - (min(wq_data$rain365) + 
                                           diff(range(wq_data$rain365))*0.5) )/ diff(range(wq_data$rain365))
wq_data$septic <- 3*(wq_data$septic - (min(wq_data$septic) + 
                                           diff(range(wq_data$septic))*0.5) )/ diff(range(wq_data$septic))

#Appropriate transformations for the eight variables
wq_data$lFRP <- log10(wq_data$FRP)
wq_data$lTP <- log10(wq_data$TP)
wq_data$lNH3 <- log10(wq_data$NH3)
wq_data$lTSS <- log10(wq_data$TSS)
wq_data$sNOx <- wq_data$NOx^0.5
wq_data$lTN <- log10(wq_data$TN)
wq_data$sEC <- wq_data$EC^0.5
wq_data$lTem <- log10(wq_data$Tem)

ys <- c("lFRP","lTP","lNH3","lTSS","lTN","sNOx","sEC","lTem")
vars <- c("frp","tp","nh3","tss","tn","nox","ec","tem")

pairs(wq_data[c("degrd","restr","rain1","rain365","channel",
                "season","diel","septic","filter","t")], 
      lower.panel = panel.smooth, upper.panel = panel.cor,
      gap=0, row1attop=FALSE)

```

#### Fig. S1-1. Correlations among the ten predictor variables. Red lines are spline smoothers, and the correlations above the diagonal are sized proportionally to the size of the correlation.

The values of the eight response variables in the 'wq_data' table are untransformed data with units as defined in the
'Unit in wq_data' field in the 'wq_vars' table. Note that for some variables, different units (as defined in the 'Unit
in paper' field) were used in the paper for presenting results.

The 'new_X' table is a template used in `wq_methods_F_model_sampling_with_Xpred.Rmd` to produce predictions for
counterfactual plots in the paper. The 'metadata' table provides a definition of each column of tables in the other
worksheets.

## Candidate models

In each model the response variable *y*: one of transformed filterable reactive phosphorus (FRP), total phosphorus (TP),
Ammonium (NH~4~^+^), total suspended solids (TSS), nitrate + nitrite (NO~x~), total nitrogen (TN), electrical
conductivity (EC) or temperature. For all eight variables, y was modeled as being drawn from a normal distribution:

$$
y_{i} = Normal(\mu_{i}, \sigma)
$$

where *y~i~* is the value in the *i*th sample, and $\mu_i$ is the mean estimate for the sample and $\sigma$ is the
residual standard deviation. Transformations to approximate a normal distribution of y were: log~10~(FRP), log~10~(TP),
log~10~(NH~4~^+^), log~10~(TSS), sqrt(NO~x~), sqrt(TN), sqrt (EC) or log~10~(temperature). To aid model convergence each
response variable was also centred and scaled.

The simplest model is coded as `m_1`, with predictor variables:

-   *degrd*, the putative degrading effect of urban stormwater runoff, represented by log~10~(*EI~S1~* + 0.1), where
    *EI~S1~ is* percentage effective imperviousness assuming stormwater control measures have no effect, with a slope
    parameter *b_d*;

-   *restr* the putative restorative effect of SCMs, represented by $\Delta EI_S$, the difference between
    log~10~(*EI~S1~* + 0.1) and log~10~(*EI~S~* + 0.1), where *EI~S~* is effective imperviousness, with impervious areas
    upstream of stormwater control measures weighted by *S*, a metric of performance, with a slope parameter *b_r*;

-   *rain1*, catchment rainfall in 24 h preceding the sample, with a slope parameter *b_p*;

-   *site_no*, an integer representing each of the 11 sites. The model has a general intercept parameter, *a*, and a
    random *site_no* effect, *a_s* for each site_no*.*

-   *time*, centred and scaled time of sample since the first sample, with a slope parameter *b_t* for each *site_no*
    (except for temperature, NO~x~ and TN for which time was a fixed effect).

More complex candidate models were calculated by adding additional variables of relevance to each response variable, as
described in the paper. To reduce the number of Stan models to be compiled, additional variables were coded as 'add1',
'add2', 'add3', and 'add4', and relevant predictors were assigned to each of these variables at the model sampling
stage. XXX general model structures were compiled in `wq_methods_B_model_compilation.Rmd`, and these were used to sample
106 specific models in `wq_methods_C_model_sampling.Rmd`.

For each general model structure, the model was sampled in a two-step process. First the model was run with
autocorrelation terms (*autoT* and *autoS*). The residuals of that model were used to calculate *autoT* (for samples
with at least one other sample from the same site in the preceding 45 days, *autoT* equals the mean residual of all such
samples) and *autoS* (for samples from L4 or D8 on days when samples were also taken from upstream sites: *autoS* equals
the mean residual of such samples).

The fitted model object for each model with *autoT* and *autoS* terms (objects ending in '\_st') was saved for
comparison in `wq_methods_D_model_selection.Rmd`.

### The effect of changing filter type was near zero and inconsequential

```{r fig.width = 6.5, fig.height = 8.5}
load("data/figS1-2_data.rda")
par(mfrow = c(3,2))
coef_plot_f(m_frp_f_coeffs,m_frp_no_f_coeffs,
            parameters = c("b_d","b_r","b_p","b_dp","b_rp","t_mu","b_add4"),
            labels = c("degrd","restr","rain1","degrd:rain1",
                       "restr:rain1","time (mean)","filter"))
title(main = "FRP  A.", adj = 0)

plot(ft_posteriors$frp_f,ft_posteriors$frp_t_mu, pch = 16,
     col = scales::alpha('blue',0.25),
     xlab = "b_f", ylab = "t_mu", las = 1)
title(main = "B.", adj = 0)

coef_plot_f(m_nh3_f_coeffs,m_nh3_no_f_coeffs,
            parameters = c("b_d","b_r","b_p","b_dp","b_rp","t_mu","b_add3"),
            labels = c("degrd","restr","rain1","degrd:rain1",
                       "restr:rain1","time (mean)","filter"))
title(main = "NH4+  C.", adj = 0)

plot(ft_posteriors$nh3_f,ft_posteriors$nh3_t_mu, pch = 16,
     col = scales::alpha('blue',0.25),
     xlab = "b_f", ylab = "t_mu", las = 1)
title(main = "D.", adj = 0)

coef_plot_f(m_nox_f_coeffs,m_nox_no_f_coeffs)
title(main = "NOx  E.", adj = 0)
plot(ft_posteriors$nox_f,ft_posteriors$nox_t, pch = 16,
     col = scales::alpha('blue',0.25),
     xlab = "b_f", ylab = "b_t", las = 1)
title(main = "F.", adj = 0)
```

#### Fig. S1-2. Coefficients (mean, 95% (thin lines) and 80% (thick lines) confidence interval) of the main experimental effects for A. FRP, C. NH~4~^+^, and D. NO\~x\~, for the best-fit model structure, with (blue) and without (red) a filter variable. The filter coefficient was near zero for FRP and NH~4~^+^, and in both cases the posterior distributions of the effects of time and filter were not correlated. In contrast, the collinear effects of time and filter (F) resulted in a negative filter effect (the opposite of what would be expected mechanistically), and the time effect shifting from near zero to positive when filter was included in the model (E). For all three variables the inclusion of a filter variable had no consequential effect on estimates of other effects (A, C, E).

Fig. S1-2 shows coefficient estimates of the best-fit models for FRP, NH~4~^+^ and NO~x~, with a filter effect, and the
same model structure without the filter effect. For FRP and NH~4~^+^, models with a filter effect were equally plausible
as equivalent models without a filter effect (as assessed by looIC). Models of NO~x~ with a filter effect were
marginally better fits than models without a filter effect, but inclusion of *filter* introduced multicollinearity into
the model (Fig. S1-2F).

The effect of using filters of larger pore size after 2003 was near zero for FRP (mean 0.03, 95% confidence intervals
-0.01, 0.07, Fig. S1-2A) and NH~4~^+^ (mean -0.02, 95% CIs -0.05, 0.05, Fig. S1-2C). Despite the raw correlation between
time and filter effects (R = 0.68, Fig. S1-1), they were uncorrelated conditional on other predictors in the models
(Fig. S1-2B, D). In contrast, the time and filter effects were collinear in the NO~x~ model (Fig. S1-2F), resulting in a
negative *filter* coefficient and a positive *t* effect, compared to a near-zero *t* effect in the equivalent model
without a *filter* effect. If filters of larger pore size were to have an effect, they would be expected to increase
concentrations: a positive effect. Because of the multicollinearity of these variables in the NO~x~ model, the *filter*
coefficient cannot be considered a reliable indicator of effect. However, the opposing directions of the *filter* and
*time* coefficients when modelled together, and the near zero effect of time in the model without a filter effect
suggest that the effect of *filter* on NO~x~ was also near zero.

We thus elected to not include a filter effect in candidate models because a) the reliable estimates of filter effect
for FRP and NH~4~^+^ suggest a near-zero effect, and b) the inclusion or exclusion of a filter effect did not change the
estimates of other effects in the models (Fig. S1-2A, B, C).

### Candidate models without *filter* effect

Table S1-1 summarises all candidate models for each response variable, and identifies the optimal models used for each
variable from the expected log-predictive density [@Vehtari_EtAl_2017].

For each model we estimated the posterior distributions of all parameters using the Markov chain Monte Carlo sampler
implemented in Stan [@CarpenterEtAl_2017]. We called Stan from R [@RCoreTeam_2020] using the library rstan
[@StanDevelopmentTeam_2020]. All $\alpha$ and $\beta$ parameters were drawn from a weakly informative normal
distribution (mean 0, standard deviation 5), except for the random site parameters $\alpha s$ and $\beta t$, which were
drawn from hyperdistributions with a mean drawn from a normal distribution with mean 0 and standard deviation 5, and
standard deviation drawn from a half-Cauchy distribution (mean 0, standard deviation 2). Each generic model structure
was compiled using the code in `wq_methods_B_model_compilation.Rmd`, and the parameters and predicted values of y for
each candidate model were sampled using the code in `wq_methods_C_model_sampling.Rmd`. Compiling and sampling the 74
models listed in Table S1-1 with and without autocorrelation terms, and with and without a filter variable (totalling
296 models) took \~14 h on a 4-CPU core system at 2.6 GHz.

For each model we drew inference from 2000 posterior samples taken from 4 unthinned chains, discarding the first 1000
values of each chain to remove the effects of the randomly generated initial values. We diagnosed convergence by
visually inspecting the MCMC chains for adequate mixing and stationarity and using the Gelman-Rubin statistic [with
values $\hat R$ \< 1.1 indicating convergence; @GelmanEtAl_2004]. We also ensured other standard diagnostic tests for
effective sample size, Bayesian Fraction of Missing Information, and saturation of tree depth
[@StanDevelopmentTeam_2020b] were satisfied.

We used the model with the highest leave-one-out estimate of out-of-sample predictive fit (ELPD~loo~:
@Vehtari_EtAl_2017) to assess responses of each variable. For each of the eight optimal models, the model structures
were edited to generate predictions under specific scenarios to produce the predictive plots in Figs. 3-5 of the paper.
The models with generated predictions were compiled using the code in `wq_methods_E_model_compilation_with_Xpred.Rmd`
and sampled using the code in `wq_methods_F_model_sampling_with_Xpred.Rmd`.

#### Table S1-1. Candidate models trialed for the eight response variables. Every model included the random site predictor and fixed predictors *degrd, restr, rain1, rain1:degrd, rain1:restr, at* and *as*, as specified in the primary model (eq. 3 in the paper). Models with Time = t[site] included a variable time effect for each site (as in eq 3), while those with Time = t included a fixed time effect. Models also differed by the specified additional predictors. The differences (± standard error) in expected log predictive density (ELPD~loo~) from the optimal model (difference = 0) are indicated for each response variable. Equally plausible models to the optimal model are indicated in bold.

```{r, warning=FALSE, message=FALSE, echo=FALSE}
# See wq_methods_D_model_selection.Rmd for origin of this xslx file
all_models <- data.frame(readxl::read_excel("data/all_models.xlsx"), stringsAsFactors = FALSE)
# Remove models with filter effect
all_models <- all_models[is.na(all_models$filter), names(all_models) != "filter"]

for(i in 1:length(vars)){
vari <- vars[i]
modsi <- all_models[tolower(all_models$wq_var) == vari,]
loosumi <- data.frame(readxl::read_excel("data/loo_sum.xlsx", sheet = vari),
                      stringsAsFactors = FALSE)
names(loosumi)[1] <- "model_code"
#Build a table identifying variables considered beyond base degrd, restr, rain1, degrd:rain1, restr:rain1, autoS, autoT
add_preds <- modsi[1,12:21]
add_preds <- paste(names(add_preds)[!is.na(add_preds)],collapse = ", ")
add_preds <- gsub("\\.",":", add_preds)
loosumij <- loosumi[loosumi$model_code == modsi$model_code[1],]
elpd_diff <- ifelse(loosumij$elpd_diff == 0, "0",
                    paste(round(loosumij$elpd_diff,1), "±", 
                          round(loosumij$se_diff,1)))
tabi <- data.frame(var = vars[i],model_code = modsi$model_code[1], 
                   time = ifelse(is.na(modsi$t[1]),"t[site]","t"),
                   add_preds = add_preds, elpd_diff = elpd_diff)
for(j in 2:dim(modsi)[1]){
add_preds <- modsi[j,12:21]
add_preds <- paste(names(add_preds)[!is.na(add_preds)],collapse = ", ")
add_preds <- gsub("\\.",":", add_preds)
loosumij <- loosumi[loosumi$model_code == modsi$model_code[j],]
elpd_diff <- ifelse(loosumij$elpd_diff == 0, "0",
                    paste(round(loosumij$elpd_diff,1), "±", 
                          round(loosumij$se_diff,1)))
tabi <- rbind(tabi,
              data.frame(var = vars[i],model_code = modsi$model_code[j], 
                   time = ifelse(is.na(modsi$t[j]),"t[site]","t"),
                   add_preds = add_preds, elpd_diff = elpd_diff))
}
if(i == 1){
  tab_out <- tabi
}else{
    tab_out <- rbind(tab_out,tabi)
  }
}


#Now, FRP, TP, NH3 and TSS used same combinations, as did NOx and TN
  tab_out1 <- rbind(
    data.frame(model_code = "FRP, TP, NH4+, TSS",time = NA, add_preds = NA, 
               stringsAsFactors = FALSE),
      tab_out[tab_out$var == "frp",-c(1,5)],
    data.frame(model_code = "NOx, TN",time = NA, add_preds = NA, 
               stringsAsFactors = FALSE),
      tab_out[tab_out$var == "nox",-c(1,5)],
    data.frame(model_code = "EC",time = NA, add_preds = NA, 
               stringsAsFactors = FALSE),
      tab_out[tab_out$var == "ec",-c(1,5)],
    data.frame(model_code = "Temperature",time = NA, add_preds = NA, 
               stringsAsFactors = FALSE),
      tab_out[tab_out$var == "tem",-c(1,5)])
  
tab_out1$elpd_diff4 <- tab_out1$elpd_diff3 <- tab_out1$elpd_diff2 <- tab_out1$elpd_diff1 <- NA
tab_out1$elpd_diff1[1:9] <- c("FRP", tab_out$elpd_diff[tab_out$var == "frp"])
tab_out1$elpd_diff2[1:9] <- c("TP", tab_out$elpd_diff[tab_out$var == "tp"])
tab_out1$elpd_diff3[1:9] <- c("NH4+", tab_out$elpd_diff[tab_out$var == "nh3"])
tab_out1$elpd_diff4[1:9] <- c("TSS",tab_out$elpd_diff[tab_out$var == "tss"])
 
tab_out1$elpd_diff1[10:26] <- c("NOx",tab_out$elpd_diff[tab_out$var == "nox"])
tab_out1$elpd_diff2[10:26] <- c("TN",tab_out$elpd_diff[tab_out$var == "tn"])

tab_out1$elpd_diff1[27:31] <- c("EC",tab_out$elpd_diff[tab_out$var == "ec"])
tab_out1$elpd_diff1[32:38] <- c("Temperature", tab_out$elpd_diff[tab_out$var == "tem"])
   
names(tab_out1)[1:4] <- c("Model code","Time parameter","Additional predictors","Difference in ELPD ± SE")
ft1 <- table_for_word(tab_out1)
ft1 <- flextable::flextable(tab_out1)
ft1 <- flextable::merge_at(ft1, i = 1, j = 1:3)
ft1 <- flextable::merge_at(ft1, i = 10, j = 1:3)
ft1 <- flextable::merge_at(ft1, i = 27, j = 1:3)
ft1 <- flextable::merge_at(ft1, i = 32, j = 4:7)
ft1 <- flextable::merge_at(ft1, i = 32, j = 1:3)
ft1 <- flextable::merge_at(ft1, j = 4:7, part = "header")
ft1
```

## Summaries of model coefficients and fits

Figs. S1-3 to S1-10 illustrate the distributions of all parameters for each optimal model, including site-specific
parameters not illustrated in the main paper. For each model, the mean predicted value for each data point is plotted
against the observed value, and the Pearson correlation coefficient is reported as an indication of model fit.

```{r, fig.width = 5, fig.height = 4.5}
# Import coefficient and fit data compiled in methods_D
oes <- get(load("data/oe_list_8vars.rda"))
coeffs_8vars <- read.csv("data/coeffs_8vars.csv")
#function for plotting figs S1-3 to S1-10
coeff_4plots <- function(wqvar){
coeffs_i <- coeffs_8vars[coeffs_8vars$var == wqvar,]
d <- oes[names(oes) == wqvar][[1]]
par(mfrow = c(2,2))
if(!wqvar %in% c("nox","tn","tem")){
  coef_plot_fig1(coeffs_i[!grepl("a_s",coeffs_i$par) & 
                            !grepl("b_t",coeffs_i$par),], 
                 xticklabs = TRUE, xlabel = "Coefficient")
}else{
  coef_plot_fig1(coeffs_i[!grepl("a_s",coeffs_i$par),], 
                 xticklabs = TRUE, xlabel = "Coefficient")
  }
  title(main = "A.", adj = 0)
  coef_plot_fig1(coeffs_i[grepl("a_s",coeffs_i$par),], 
                 xticklabs = TRUE, xlabel = "Coefficient")
  title(main = "B. site", adj = 0)
if(!wqvar %in% c("nox","tn","tem")){
  coef_plot_fig1(coeffs_i[grepl("b_t",coeffs_i$par),], 
                 xticklabs = TRUE, xlabel = "Coefficient")
  title(main = "C. time[site]", adj = 0)
  }
par(mar = c(4,4,1,1))
plot(d$y, d$y_pred_mean, pch = 16,col = scales::alpha('blue',0.25),
     xlab = "Observed y", ylab = "Predicted y", axes = FALSE)
abline(0,1, col = "black", lty = 3)
oe <- lm(y_pred_mean ~ y, data = d)
abline(oe, col = "red")
axis(1, las = 1); axis(2, las= 1); box(bty = "l")
title(main = paste("  R =", round(cor(d$y, d$y_pred_mean),2)), 
      adj = 0, font.main = 3, line = -2)
panel_label <- ifelse(wqvar %in% c("nox","tn","tem"),"C.","D.")
  title(main = panel_label, adj = 0)}

coeff_4plots("frp")
```

#### Fig. S1-3. FRP. A. Median coefficient estimates (points with thick and thin error bars representing 90 and 95% confidence intervals, respectively) for the fixed effects (and the mean site effect). B. site effects. C. time effect for each site. D. plot of all observed vs predicted values of (transformed, scaled) FRP concentration. The red line shows line of best fit, and the dotted black line shows the 1:1 relationship.

```{r, fig.width = 5, fig.height = 4.5}
coeff_4plots("tp")
```

#### Fig. S1-4. TP. Median coefficient estimates (points with thick and thin error bars representing 90 and 95% confidence intervals, respectively) for the fixed effects (and the mean site effect). B. site effects. C. time effect for each site. D. plot of all observed vs predicted values of (transformed, scaled) TP concentration. The red line shows line of best fit, and the dotted black line shows the 1:1 relationship.

```{r, fig.width = 5, fig.height = 4.5}
coeff_4plots("tn")
```

#### Fig. S1-5. TN. Median coefficient estimates (points with thick and thin error bars representing 90 and 95% confidence intervals, respectively) for the fixed effects (and the mean site effect). B. site effects. C. plot of all observed vs predicted values of (transformed, scaled) TN concentration. The red line shows line of best fit, and the dotted black line shows the 1:1 relationship.

```{r, fig.width = 5,  fig.height = 4.5}
coeff_4plots("nox")
```

#### Fig. S1-6. NO~x~ Median coefficient estimates (points with thick and thin error bars representing 90 and 95% confidence intervals, respectively) for the fixed effects (and the mean site effect). B. site effects. C. plot of all observed vs predicted values of (transformed, scaled) NO~x~ concentration. The red line shows line of best fit, and the dotted black line shows the 1:1 relationship.

```{r, fig.width = 5, fig.height = 4.5}
coeff_4plots("nh3")
```

#### Fig. S1-7. NH~4~^+^. A. Median coefficient estimates (points with thick and thin error bars representing 90 and 95% confidence intervals, respectively) for the fixed effects (and the mean site effect). B. site effects. C. time effect for each site. D. plot of all observed vs predicted values of (transformed, scaled) NH~4~^+^ concentration. The red line shows line of best fit, and the dotted black line shows the 1:1 relationship.

```{r, fig.width = 5, fig.height = 4.5}
coeff_4plots("tss")
```

#### Fig. S1-8. TSS A. Median coefficient estimates (points with thick and thin error bars representing 90 and 95% confidence intervals, respectively) for the fixed effects (and the mean site effect). B. site effects. C. time effect for each site. D. plot of all observed vs predicted values of (transformed, scaled) TSS concentration. The red line shows line of best fit, and the dotted black line shows the 1:1 relationship.

```{r, fig.width = 5, fig.height = 4.5}
coeff_4plots("ec")
```

#### Fig. S1-9. EC. A. Median coefficient estimates (points with thick and thin error bars representing 90 and 95% confidence intervals, respectively) for the fixed effects (and the mean site effect). B. site effects. C. time effect for each site. D. plot of all observed vs predicted values of (transformed, scaled) EC concentration. The red line shows line of best fit, and the dotted black line shows the 1:1 relationship.

```{r, fig.width = 5, fig.height = 4.5}
coeff_4plots("tem")
```

#### Fig. S1-10. Temperature. A. Median coefficient estimates (points with thick and thin error bars representing 90 and 95% confidence intervals, respectively) for the fixed effects (and the mean site effect). B. site effects. C. plot of all observed vs predicted values of (transformed, scaled) temperature. The red line shows line of best fit, and the dotted black line shows the 1:1 relationship.

## Compilation of tables used in figures

The file `wq_methods_E_model_compilation_with_Xpred.Rmd` compiles a variation of the optimal model structure for each
variable to include generating predictions to a test dataset. It creates 5 Stan model objects: m_1\_st_p (for EC),
m_1\_x_st_p (for TP and TSS), m_1\_xx_st_p (for FRP and NH~4~^+^), m_1ft_xxx_int_st_p (for NO~x~ and TN), and
m_3ft_sdr_int_st_p (for Temperature). `wq_methods_F_model_sampling_with_Xpred.Rmd` samples each of the 8 optimal models
and saves each model fit with a file name ending in the suffix "\_p". `wq_methods_G_model_prediction.Rmd` uses the model
fits to compile the following tables:

-   new_X\_[varname] is a table of predictions to the new_X set of scenario data, used to plot Figs. 2 and 5. Because
    the set of predictor variables differs among variables, a separate table was compiled for each variable, and the
    eight tables were saved as worksheets in "data/prediction_set.xlsx".

-   statistics (50th, 95th, 90th percentile) for predictor coefficients were compiled into a single table,
    "coeffs_8vars.csv". The models sampled for prediction to new data used unscaled response variables (cf models in
    wq_methods_C, which were scaled) to permit simpler calculation of predictions. The coefficients for these models are
    thus saved as "data/coeffs_8vars_unscaled.csv", to distinguish them from the models sampled in
    wq_methods_D\_model_selection.Rmd, which were scaled to permit plotting of coefficients on a comparable scale as in
    Fig. 2.

-   the mean predicted value for each data point, together with the observed value were saved as a table [var]\_oe for
    each variable, and the eight tables were saved as a list (i.e. an R object), "data/oe_list_8vars.rda" (used in Figs.
    S1-3 to S1-10).

-   A table of differences between S, predicted values given achieved SCM implementation, N, predicted values assuming
    no SCM implementation, and R predicted values in the absence of stormwater (and septic) impacts, for each value at
    each of the six experimental sites, saved as "data/comparisons.csv" used to plot Fig. 4.

Neither the model structure objects nor the fitted model objects were saved in the OSF repository, because of their
large sizes: the code in the model compilation and model sampling documents needs to be run to recreate them.

## References
